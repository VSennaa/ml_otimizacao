# Valida√ß√£o de Modelos e M√©tricas de Avalia√ß√£o para Classifica√ß√£o de Inadimplentes

## üéØ Sobre o Projeto

Este projeto tem como objetivo principal aprimorar os conhecimentos acerca de t√©nicas de aprendizado de m√°quina, investigando, de mandeira hipot√©tica, um caso de identifica√ß√£o de clientes inadimplentes para uma empresa de empr√©stimo de autom√≥veis. Utilizando t√©cnicas de Machine Learning, o projeto foca na classifica√ß√£o de clientes em adimplentes e inadimplentes, testando e otimizando diferentes modelos de classifica√ß√£o.

## üìä Fonte dos Dados

Os dados utilizados neste projeto foram carregados a partir do seguinte CSV:

    url = 'https://raw.githubusercontent.com/VSennaa/ml_defaulters_classifier/refs/heads/main/emp_automovel.csv'

## üõ†Ô∏è Metodologia

O projeto seguiu as seguintes etapas:

1.  **An√°lise Explorat√≥ria e Pr√©-processamento:**
    * Carregamento e c√≥pia dos dados.
    * Verifica√ß√£o inicial dos tipos de dados.
    * Visualiza√ß√£o da distribui√ß√£o de vari√°veis como `receita_cliente` e `anuidade_emprestimo` em rela√ß√£o √† inadimpl√™ncia usando histogramas e boxplots (com `plotly.express`).

2.  **Cria√ß√£o de Modelo Inicial:**
    * Um modelo de √Årvore de Decis√£o (`DecisionTreeClassifier`) foi criado como baseline, com `max_depth=10` e `random_state = SEED` (onde `SEED = 123`).

3.  **Divis√£o dos Dados:**
    * Os dados foram divididos em conjuntos de treino, valida√ß√£o e teste para uma avalia√ß√£o robusta dos modelos.
        * Primeira divis√£o: 15% para teste (`x_teste`, `y_teste`), 85% restante para treino/valida√ß√£o.
        * Segunda divis√£o (do conjunto de 85%): 15% para valida√ß√£o (`x_val`, `y_val`), resultando em aproximadamente 72.25% do total para treino (`x_treinoP`, `y_treinoP`).
    * A estratifica√ß√£o (`stratify=y`) foi utilizada para manter a propor√ß√£o das classes.

4.  **M√©tricas de Avalia√ß√£o:**
    * **Matriz de Confus√£o:** Para visualizar os Verdadeiros Positivos (VP), Falsos Positivos (FP), Verdadeiros Negativos (VN) e Falsos Negativos (FN).
    * **M√©tricas Derivadas:** Acur√°cia, Precis√£o, Recall e F1-Score.
    * **Curvas de Avalia√ß√£o:** Curva ROC e Curva de Precis√£o x Recall.
    * **Relat√≥rio de Classifica√ß√£o:** `classification_report` do Scikit-learn.

5.  **Valida√ß√£o Cruzada:**
    * Utiliza√ß√£o de `KFold` e `StratifiedKFold` (com `n_splits=5`) para uma avalia√ß√£o mais consistente, mitigando a depend√™ncia de uma √∫nica divis√£o dos dados.
    * A fun√ß√£o `cross_validate` foi empregada para obter m√∫ltiplas m√©tricas.
    * Foi definida uma fun√ß√£o `media_desvio` para reportar a m√©dia e o desvio padr√£o das m√©tricas obtidas na valida√ß√£o cruzada.

6.  **Compara√ß√£o e Otimiza√ß√£o de Modelos:**
    * **Modelos Testados:**
        * √Årvore de Decis√£o (`DecisionTreeClassifier`)
        * Random Forest (`RandomForestClassifier`)
        * K-Nearest Neighbors (`KNeighborsClassifier`)
        * Regress√£o Log√≠stica (`LogisticRegression`)
    * **Balanceamento de Dados (nos dados de treino):**
        * **Oversampling:** SMOTE (`imblearn.over_sampling.SMOTE`)
        * **Undersampling:** NearMiss (`imblearn.under_sampling.NearMiss`)
        * **Combinado:** SMOTEENN (`imblearn.combine.SMOTEENN`)
    * **Pipeline:**
        * Uso de `imblearn.pipeline.Pipeline` para encadear etapas de pr√©-processamento (como `StandardScaler` para Regress√£o Log√≠stica e KNN) e balanceamento com o treinamento do modelo.

## üìà Resultados e Avalia√ß√£o

Ap√≥s a aplica√ß√£o de valida√ß√£o cruzada estratificada e t√©cnicas de balanceamento, os resultados de **Recall** (m√©trica priorizada para minimizar falsos negativos - clientes inadimplentes n√£o identificados) foram comparados para os diferentes modelos e t√©cnicas de balanceamento:

| T√©cnica de Balanceamento | KNN      | DT       | RNF      | LR       |
| :----------------------- | :------- | :------- | :------- | :------- |
| SMOTE                    | 0.351453  | 0.261913  | 0.237963  | 0.590671  |
| NearMiss                 | 0.778004  | 0.812921  | 0.783486  | 0.653779  |
| SMOTEENN                 | 0.416810  | 0.393359  | 0.358942  | 0.760537  |


Foi gerado um gr√°fico de barras para visualiza√ß√£o comparativa desses resultados.
O modelo final destacado no notebook para uma an√°lise de desempenho nos dados de teste foi a **Regress√£o Log√≠stica com NearMiss e StandardScaler**, cuja matriz de confus√£o foi plotada.
<p align="center">
  <img src="comparacao_balanceamentos.png" alt="Compara√ß√£o do Recall M√©dio por Modelo e T√©cnica de Balanceamento" width="600" />
</p>

<p align="center">
  <img src="matrizdeconfusao.png" alt="matrizdeconfusao" width="600" />
</p>
## üíª Principais Bibliotecas Utilizadas

* `pandas`
* `numpy`
* `matplotlib.pyplot`
* `plotly.express`
* `sklearn` (tree, model_selection, metrics, ensemble, neighbors, linear_model, preprocessing)
* `imblearn` (over_sampling, under_sampling, combine, pipeline)

## üöÄ Como Utilizar/Reproduzir

1.  Certifique-se de ter todas as bibliotecas listadas acima instaladas.
2.  Fa√ßa o download do notebook (`.ipynb`).
3.  Execute as c√©lulas sequencialmente em um ambiente Python (como Jupyter Notebook, Google Colab).
4.  O `SEED` utilizado para reprodutibilidade foi `123`. A profundidade m√°xima (`PROFUNDIDADE`) para √°rvores foi `10`.

## üìß Contato

Vinicios Rodrigo
vsennamart@gmail.com
